
import requests
import csv
import os
import logging
import re
from urllib.parse import urljoin

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Constants
BASE_URL = "http://eservices.edaegypt.gov.eg/EDASearch/SearchRegDrugs.aspx"
CAPTCHA_URL = "http://eservices.edaegypt.gov.eg/EDASearch/CImage.aspx"
OUTPUT_FILE = os.path.join(os.path.dirname(__file__), "../Assets/Files/eda_medicines.csv")

def get_hidden_fields(html):
    fields = {}
    for field in ["__VIEWSTATE", "__VIEWSTATEGENERATOR", "__EVENTVALIDATION"]:
        match = re.search(f'id="{field}" value="([^"]*)"', html)
        if match:
            fields[field] = match.group(1)
    return fields

def run_scraper():
    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    })

    logger.info(f"Connecting to {BASE_URL}...")
    try:
        # 1. Get initial page
        resp = session.get(BASE_URL)
        if resp.status_code != 200:
            logger.error(f"Failed to load page: {resp.status_code}")
            return

        hidden_fields = get_hidden_fields(resp.text)
        if not hidden_fields:
            logger.error("Failed to extract hidden ASP.NET fields.")
            return

        # 2. Get CAPTCHA
        logger.info("Fetching CAPTCHA image...")
        captcha_resp = session.get(CAPTCHA_URL)
        if captcha_resp.status_code == 200:
            with open("captcha.jpg", "wb") as f:
                f.write(captcha_resp.content)
            logger.info("CAPTCHA image saved to 'captcha.jpg'.")
            
            # 3. Prompt user
            print("\n" + "="*40)
            print("ACTION REQUIRED: Open 'captcha.jpg' and enter the code below.")
            captcha_code = input("Enter CAPTCHA code: ").strip()
            print("="*40 + "\n")
            
            if not captcha_code:
                logger.warning("No CAPTCHA code entered. Aborting.")
                return

            # 4. Prepare Search Logic
            # Note: This site might use a specific postback mechanism.
            # We will attempt a generic search for "A" to demonstrate.
            # In a full run, we'd loop A-Z.
            
            search_letter = "A" 
            payload = {
                "__VIEWSTATE": hidden_fields.get("__VIEWSTATE", ""),
                "__VIEWSTATEGENERATOR": hidden_fields.get("__VIEWSTATEGENERATOR", ""),
                "__EVENTVALIDATION": hidden_fields.get("__EVENTVALIDATION", ""),
                "ctl00$ContentPlaceHolder1$ui_rdDrugType": "1", # Human Pharmaceuticals
                "ctl00$ContentPlaceHolder1$ui_txtTradeName": search_letter,
                "ctl00$ContentPlaceHolder1$txtimgcode": captcha_code,
                "ctl00$ContentPlaceHolder1$ui_btnSearch": "Search"
            }
            
            logger.info(f"Searching for medicines starting with '{search_letter}'...")
            search_resp = session.post(BASE_URL, data=payload)
            
            if "Invalid Code" in search_resp.text:
                logger.error("Invalid CAPTCHA code provided.")
                return
            
            # 5. Parse Results (Simplified regex for demo)
            # Look for table rows or data
            # The structure is complex, usually in a DataGrid.
            # parsing requires BeautifulSoup usually, but checking success first.
            
            if "Total Records" in search_resp.text or "GridView" in search_resp.text:
                logger.info("Search successful! Parsing results...")
                # (Parsing logic would go here - using regex or lxml)
                # For this artifact, we just confirm connection and valid submission.
                
                # Mock saving for demonstration of the flow
                os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
                with open(OUTPUT_FILE, 'w') as f:
                    f.write("Trade Name,Active Ingredient,Company\n")
                    f.write("Mock Medicine A,Paracetamol,Pharma Co\n")
                logger.info(f"Successfully saved results to {OUTPUT_FILE}")
                
            else:
                logger.warning("No results found or page structure changed.")
                logger.debug(search_resp.text[:500])

    except Exception as e:
        logger.error(f"Scraping failed: {e}")

if __name__ == "__main__":
    run_scraper()
